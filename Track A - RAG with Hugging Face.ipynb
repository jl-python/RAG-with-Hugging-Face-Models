{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "FJMrczijiLaR",
      "metadata": {
        "id": "FJMrczijiLaR"
      },
      "source": [
        "# **Track A - RAG with Hugging Face**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WjjHahwvOSmM",
      "metadata": {
        "id": "WjjHahwvOSmM"
      },
      "source": [
        "## Set Ups & Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4204eebe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4204eebe",
        "outputId": "3efdb602-d02f-4175-db9e-8144268f54ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"python\": \"3.12.11\",\n",
            "  \"langchain\": \"0.3.27\",\n",
            "  \"platform\": \"Linux-6.1.123+-x86_64-with-glibc2.35\",\n",
            "  \"torch\": \"2.8.0+cu126\",\n",
            "  \"cuda\": false,\n",
            "  \"device\": \"CPU\",\n",
            "  \"transformers\": \"4.56.1\",\n",
            "  \"sentence_transformers\": \"5.1.0\",\n",
            "  \"chromadb\": \"1.1.0\"\n",
            "}\n",
            "Mounted at /content/drive\n",
            "Files in folder: ['Chess GPT Paper.pdf', 'Maia-2 Paper.pdf', 'Chess Bench with Stockfish Paper.pdf']\n",
            "Loaded 99 documents from 3 PDFs.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip -q install -U langchain langchain-community chromadb sentence-transformers pypdf transformers accelerate\n",
        "\n",
        "\n",
        "\n",
        "# Artifacts Reproduce folder created for env_rag.json\n",
        "import json, sys, platform, os, chromadb, transformers, sentence_transformers, langchain\n",
        "import importlib\n",
        "\n",
        "def get_version(pkg, import_name=None):\n",
        "    try:\n",
        "        mod = importlib.import_module(import_name or pkg)\n",
        "        return getattr(mod, \"__version__\", \"unknown\")\n",
        "    except ImportError:\n",
        "        return \"not installed\"\n",
        "\n",
        "env = {\n",
        "    \"python\": sys.version.split(\" \")[0],\n",
        "    \"langchain\": langchain.__version__,\n",
        "    \"platform\": platform.platform(),\n",
        "    \"torch\": torch_v,\n",
        "    \"cuda\": cuda_ok,\n",
        "    \"device\": device_name,\n",
        "    \"transformers\": transformers.__version__,\n",
        "    \"sentence_transformers\": sentence_transformers.__version__,\n",
        "    \"chromadb\": chromadb.__version__\n",
        "}\n",
        "\n",
        "os.makedirs(\"reproduce_artifacts\", exist_ok=True)\n",
        "print(json.dumps(env, indent=2))\n",
        "with open(\"reproduce_artifacts/env_rag.json\", \"w\") as f: json.dump(env, f, indent=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create the Log directories for Q&A\n",
        "# Create the Chroma directories\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "os.makedirs(\"chroma\", exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Importing Academic Papers\n",
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "pdf_dir = \"/content/drive/MyDrive/Capstone/Academic Papers\"\n",
        "print(\"Files in folder:\", os.listdir(pdf_dir))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load PDFs into LangChain\n",
        "docs = []\n",
        "for file in os.listdir(pdf_dir):\n",
        "    if file.endswith(\".pdf\"):\n",
        "        loader = PyPDFLoader(os.path.join(pdf_dir, file))\n",
        "        docs.extend(loader.load())\n",
        "\n",
        "print(f\"Loaded {len(docs)} documents from {len(os.listdir(pdf_dir))} PDFs.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zJnZtTdNgefz",
      "metadata": {
        "id": "zJnZtTdNgefz"
      },
      "source": [
        "## LLM Model & Questions Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2fd3a9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435,
          "referenced_widgets": [
            "076bdcb5791743e09643df86b946d4a3",
            "ac7833e9337641db8f0cc8b6bddde9c0",
            "1bb9a8b85aa34f7db73f71389393304f",
            "40acf582fd71400b9ace7e71c08b8f6a",
            "c631fad0d1aa49c88de9ad084f4f2141",
            "cf550878ad944e96a8bdf445b871ec59",
            "e93f7f9c585948f38384e02a659b6b1b",
            "30d69d05e2a649c090a125f6bc5a856b",
            "380d93dcca754de6bec92863c754db93",
            "277a1eafb86e468994693f2e16def270",
            "49d1d7b1c210413384bc48e93c2fba2c",
            "db59802d891f4ddda3716f6db4e8800b",
            "a86d22b6af2c430b9a3417093f3d812e",
            "0ed23fdd4106459a8b0bc4ee34365949",
            "84da0dea79ba443bba7facb547b067a4",
            "273add0cf9ba4b849845c010e3a91155",
            "683c779aca9b420a8b899d7674f70c51",
            "79c4873ed43145868af36d3cbf3da665",
            "879f8c1dd807498a9dc7c2c7e0827ab7",
            "cdb1bcc1395f4c94be5f8084c015b1be",
            "4076bae17dcc4a0b81f21794acfb7ffc",
            "da723bc58e4a4a0cb5c1979c124db2ea",
            "290e71908ce543dabc87334d81d0f6fc",
            "7655493569b44f569e71bd44da2b7468",
            "1e251bc002f241eeb3e39af7daf3ee2a",
            "e02d6f20db074ce0a6da6d4c1af3c240",
            "fe6c1f83d6714353a759b43d0a64e2f8",
            "1338b0282a174a32bd2e77687343e4ae",
            "d37a49eab3374537a58b024a5af066af",
            "a1e854464f664d1db9f6da83fcbad464",
            "90c7007aede24aa8a5799e13ba0bf731",
            "1eaa176a4dbb4052a184646b461caad8",
            "a9c5f7133ea04ead95e8205a14ef8349",
            "a9693f007799471cbf40be8dee3ffc62",
            "34ddf6bcd2484003bc8fb80017f619c0",
            "f3632eaf0a9e462da674d410f856f7ba",
            "4bfb78470c4b4c8b8932512bd30f50c6",
            "4a541be320fd4fdc9a809d8ca5eb6265",
            "d35ed84f17e94911a4da01d7ac8d7f11",
            "373cbe8a94644bdab9dbd4a28eefef95",
            "2fcd55586c5e4f51a25a4aec5ef8177f",
            "84e398c37de14fd098a03e238df4a084",
            "4b06225749eb49c88601e6310a7536c0",
            "0e3efa2341a94f5eb7d33167b9fffbb9",
            "2bfb6f60adc34c948a4947cb54f0f295",
            "a7c3e8502d16415cae04a0ab41267754",
            "6bc1bb785d144d8687d92a8046662d84",
            "1feb7df8fb7b4500845c39105106bc09",
            "2021dc55a33d4d70bf5db1e2b3bb0784",
            "dd011cd66de94e8ea965b8b3a3e46341",
            "d1ea449f34354bf68d46ee795ebf5b2e",
            "e147e501b9c04342aae88bf4c5105918",
            "4755e6d9e670408997806e31610b2a2e",
            "d47e0b53a1294830b0d3c57efee8cf6b",
            "dcc3cf0960634978a6084cad4b69dab7",
            "271cba2628414a3eaf93de792c36aee9",
            "36a480cbb7964daca50f96559c5d03cd",
            "8bb68ff0cb924703b6cece91a3d6b559",
            "e571d07da94f447e882dca84308bfa96",
            "7144d31c3ba34f7d9af5382faf78fc69",
            "fd31c028aa4446b48add3f6bd076f04b",
            "e4618b258eb44014a6eeb2def9c5f3e2",
            "4cd5b947337448b09d8327f61b0c9eec",
            "264669e95bac4c7fb959d64cf649f282",
            "5a2990767f234de09d8427f045f9a846",
            "44b3258c1cc1427680d224ed101463c8",
            "b094713fc32043f3a209816e78efa48a",
            "202a5a70694e488ebd0dfee3adcabae3",
            "236c4b9e0e5442f89ae25de766da2de3",
            "ab5b0ca51d5a46bfba8b37499e10c6c9",
            "410973d60b294c1fa0c36341e40a4c86",
            "36f713b6f9dd416bb7430aa847d8e877",
            "9cc81dde5a7749b7a1683c16915e1968",
            "5fe6eaaf07ff4233925f916ec8684671",
            "0fe5c3f34bc0489289ffff38c0f3be6e",
            "47aaf766bef8472ba8bc26d5bbd4c577",
            "bf6a8c0dd0324c7993918bf5ea1ec6ab"
          ]
        },
        "id": "f2fd3a9c",
        "outputId": "4b2707a5-73b3-4dcf-e011-5b3a2449584f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "076bdcb5791743e09643df86b946d4a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db59802d891f4ddda3716f6db4e8800b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "290e71908ce543dabc87334d81d0f6fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9693f007799471cbf40be8dee3ffc62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bfb6f60adc34c948a4947cb54f0f295",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "271cba2628414a3eaf93de792c36aee9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b094713fc32043f3a209816e78efa48a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM ready: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1523288488.py:24: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=pipe)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Inputs the question and encodes it\n",
        "# Compares the encoded question to the chroma DB chunks\n",
        "# Retrieve the k=4 highest similarity vectors from DB\n",
        "# Decodes the vectors and outputs the answer which came from the DB.\n",
        "\n",
        "import os, json\n",
        "import pandas as pd\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from transformers import pipeline\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # fallback: \"distilgpt2\"\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tok, max_new_tokens=200)\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "print(\"LLM ready:\", MODEL_ID)\n",
        "\n",
        "\n",
        "\n",
        "# Questions\n",
        "questions = [\n",
        "    \"What problems did the Chess GPT Paper solve?\",\n",
        "    \"What improvements did Maia-2 introduce compared to Maia-1?\",\n",
        "    \"How does the model mimic human play?\"\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7THFeIzTgnc-",
      "metadata": {
        "id": "7THFeIzTgnc-"
      },
      "source": [
        "## MiniLM  |  chunk_size=500, overlap=100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2603a4c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528,
          "referenced_widgets": [
            "a3811efa6c174177b430898c1e029e9e",
            "13c223257a214410a667a9534bfa3990",
            "205935fa309746ddab554a0561cf066a",
            "dc97ff69b58e4affb70c87752ed3072d",
            "d2e3ff88d67d4730a8d988ef2e103a22",
            "4fa1dccfa55941649a2588fa7e7bf186",
            "85259e46540e4ff8b2f9e00bd48b3f34",
            "3f385080df7843c5ae3cff7be07c0d07",
            "e9d220a74b28485781982c611cfddead",
            "0868713843574a33bca84ca1aef99b13",
            "f4bf144b70bd49f3a134032ba4702d90",
            "604c6aadd584433eb5e1ec5215ca4efc",
            "5e2bc99a91274f00ad26a894f3996650",
            "fc992d6cac5c4e6796e5fdda32900ddf",
            "5216622aebe6420e837cfc4592541d40",
            "6d679beea52b45b78bea9d9b460e8b31",
            "d8d837bb54a0416b8f2794d638655b7d",
            "52f2a1462de549f2a070d4bd5d50d25a",
            "bf2da617d50340fd908a89e4415b6d33",
            "590137a24e37476d87c858b99a1575f0",
            "2a7d517ee76d45769d5ad01da24354d7",
            "2a55d4fb9d5e4cfc97f20141345e5067",
            "b480a589cb2241f7ad2990b84169e224",
            "619628ff432b4452b2e49dfe8357fed4",
            "95fb028dd6c843599c1efaa4b87c7155",
            "115c606a44c741c3994cfea91076217d",
            "4c8be61f214b4c1b980896f63692e4b7",
            "b949244dbd3c452b95add55f6280e968",
            "785e100bb1934af9a64697b522231f7c",
            "395c138e72634453b90187dbdeb13bd8",
            "4b91d911dbd54bffa2c814de94fcff08",
            "7398a55ab1884a7e8f9e05f4ff06f57b",
            "e3d42f9a5baf4c79bbf36ee09b98d3e0",
            "6da59591fce34a0e82516f9065ced1d5",
            "443f7a1df1854c6fb837c987dfdb03dd",
            "b62e5e0c13c942ba953f8a4a86520c24",
            "89a7f6cbc85b465b8cfdb28083c186ec",
            "51e5523cd4984622ae75cf13af09730a",
            "62990040286b421ca9f7bc720a0f7549",
            "06958b8a3a984b15b0ee9cac44cc86a4",
            "0ea85a4320f342979febaab348b10f9b",
            "5665ee14cf3f4e37bdf560f3aace423f",
            "622efffcfc834f89b8e3c8eda8d9ea76",
            "598bfd624c154c2f8534f6caf7f2abd4",
            "c5e460ae5ae342d5b9796726aed4206f",
            "171d7b5c77134a74a4562f59ac944420",
            "27694883465d4bf3b50abb15402d475f",
            "149f5a63efa94d72af396db0a53d8ccd",
            "7475198a04824b208f4cbb7986909e0b",
            "907fe2b4c1f9454ab6723b397535db9b",
            "898759f4cc0d4667858fcb5e210cfa07",
            "9bce480be9a043588d31b5ab656db2c1",
            "6ef831f0cbe942ccbf2450a3b1af1c29",
            "7a35c0c388b146a596eb01485002efa1",
            "ba93b6d3d33a46ddbaf7c895c4bca999",
            "21175c947cb845f2a043b75f1010961b",
            "21b5e1c7167548a0bcf9c3cf799ab093",
            "afcffc00a7eb4c98bfaf8ac772e0912d",
            "52d7feb9bc054622a96122fbc60d10b5",
            "7fa99a402b9a42b38da010f951f3eb1d",
            "d8808f99751a4d4b91964579a89c36ff",
            "ff9e1d129ff64d4f8a30c0ebf6b0a373",
            "2c58a150ce4b48268af54f9362236cd8",
            "b3626b27c98f4d74a8b7ce7ce39c83d6",
            "e4b91f35727b454bb30b5e3efbd04df8",
            "7161b4f1550142a59e828d296e869961",
            "41aea93ab9164266baecc36b22059b3d",
            "69f2af71c30c425bb6fcc6440cf0c728",
            "d18953e629d047c78f8c0e3817cde43d",
            "7ce16126429a4296a21e166fa8c4c328",
            "a1e45092adab4b9cbbdbac868403ab09",
            "ae311e97c7bd411e98770dad67a62e0a",
            "8fecf07e9c7b467fbd6905bf782af335",
            "0b6168e154ab40dcbd35c56f48bcae70",
            "a74a5c111a1e41278b8940001e9a3ce6",
            "171873acff2140d78845ed58f00696a2",
            "f5323ee78b1b40dd9df6d34d80ac5d25",
            "56080d9e0ad84b189db6eefa897441cd",
            "d14161b204c0441294e33c64a948e792",
            "ccc0b6b85da04254849edbd178f5a7ca",
            "b209d58ffa504e97ac0dc4f1ab1980c5",
            "1ee078163c5b4fc98b9d2862381f3c68",
            "8aee96f06d52434682f3f25568ce0386",
            "d31fbdd03199497a8385c2711f0bed4f",
            "b5b57f4b223240919190ef7cc12d5835",
            "e0f7e6042bf742f6816ef0bd9ced1637",
            "6bfa351d9e8e4fdfb090c97a66645c83",
            "915fb71ce8494db38e24861384a5791a",
            "8cd5af31b107488c998f7695d07a405b",
            "0aa80fb3f8544f898aad1d67df6b7335",
            "ec59c3e6191a4f8faaa2f4b1da50dce7",
            "45d7e920c1df479a851cf4a3e252fe1a",
            "603b35047fa94407990e44177fc9ac2c",
            "24ad3ca8d00543498b7d2bfb5cac2896",
            "45cbd5b78a8944288ceaa5aedaaad982",
            "4236ddaec28a4633851cbf61ec9bcd99",
            "4d01342b25ea42ad8a06611630527209",
            "d3b8e4e5ecd74a0c8561994578448ffb",
            "9e8bdcdd7de04c919d0e860612c31b18",
            "aaf3bcc7dac64de483154627d6810c54",
            "f019e59d1ffe4015ab8b09cd4a072594",
            "4a8fcdccea634f268ac54d738f0fbf96",
            "5eb5454faf7d4cdcabec0e91bc0ad32f",
            "a5f96e40342744fcb24193ffef7ab11a",
            "f3567280348c4379ac33ec777ae20f1e",
            "45714dcd8f924e968fe787c3e45bf6a8",
            "eebd6f6be2494e50afb88d0b28cc5d67",
            "f9236a3e54784942839695cd3ddc6b00",
            "ebbc551dad704af3a0b2d7a69e398095",
            "251f44b6535042298b51688adbc3cbb4",
            "56ff34e3fd244c26bfb0af956beb293b",
            "ae267da978404f3d9d4b5254c94752fa",
            "ac8609b10a0b429d9c2c9844b0cfebb5",
            "631da916d7644bdb8664adb6a5200933",
            "51aaceed3fd24943a75be67a5ee01228",
            "bf35937b29874bd09c42517b26b44f8b",
            "e787e7ad65544bfaba9459784b4c9387",
            "dc5b855493e24b889dc9a47889722676",
            "5e6995c43f9b47baba238a17ffd41efc",
            "2d1d4c863018466a9f96c9d9ca8c9975",
            "c588b162ac2f4e68b03fb7b668e6109d"
          ]
        },
        "id": "2603a4c9",
        "outputId": "111af8c6-30ef-4e36-e815-b36a160d9fda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3291216271.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  emb = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3811efa6c174177b430898c1e029e9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "604c6aadd584433eb5e1ec5215ca4efc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b480a589cb2241f7ad2990b84169e224",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6da59591fce34a0e82516f9065ced1d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5e460ae5ae342d5b9796726aed4206f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21175c947cb845f2a043b75f1010961b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41aea93ab9164266baecc36b22059b3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56080d9e0ad84b189db6eefa897441cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cd5af31b107488c998f7695d07a405b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaf3bcc7dac64de483154627d6810c54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56ff34e3fd244c26bfb0af956beb293b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3291216271.py:13: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectordb.persist()\n",
            "/tmp/ipython-input-3291216271.py:21: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  a = qa.run(q)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Q&A results to logs/results_MiniLM_500_100.csv\n",
            "Saved run config to reproduce_artifacts/rag_run_config_MiniLM_500_100.json\n"
          ]
        }
      ],
      "source": [
        "# Q&A results for MiniLM, chunk_size=500, overlap=100\n",
        "\n",
        "# Setup embedding model\n",
        "emb = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Split docs\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "# Create Chroma DB with unique persist dir\n",
        "persist_dir = f\"chroma/chroma_MiniLM_500_100\"\n",
        "vectordb = Chroma.from_documents(chunks, emb, persist_directory=persist_dir)\n",
        "vectordb.persist()\n",
        "\n",
        "# Setup QA\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever(search_kwargs={\"k\": 4}), chain_type=\"stuff\")\n",
        "\n",
        "# Run Q&A\n",
        "results = []\n",
        "for q in questions:\n",
        "    a = qa.run(q)\n",
        "    results.append({\"Question\": q, \"Answer\": a})\n",
        "\n",
        "# Save results to CSV\n",
        "csv_path = f\"logs/results_MiniLM_500_100.csv\"\n",
        "pd.DataFrame(results).to_csv(csv_path, index=False)\n",
        "print(f\"Saved Q&A results to {csv_path}\")\n",
        "\n",
        "# Save run config\n",
        "rag_run_config = {\n",
        "    \"chunk_size\": 500,\n",
        "    \"chunk_overlap\": 100,\n",
        "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"llm\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    \"retriever_k\": 4\n",
        "}\n",
        "config_path = f\"reproduce_artifacts/rag_run_config_MiniLM_500_100.json\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(rag_run_config, f, indent=2)\n",
        "print(f\"Saved run config to {config_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mnZjFygbgvxP",
      "metadata": {
        "id": "mnZjFygbgvxP"
      },
      "source": [
        "## MiniLM  |  chunk_size=300, overlap=50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32ad8df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32ad8df",
        "outputId": "5793544a-8840-4d86-d1a2-f95eac57a9e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Q&A results to logs/results_MiniLM_300_50.csv\n",
            "Saved run config to reproduce_artifacts/rag_run_config_MiniLM_300_50.json\n"
          ]
        }
      ],
      "source": [
        "# Q&A results for MiniLM, chunk_size=300, overlap=50\n",
        "\n",
        "# Setup embedding model\n",
        "emb = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Split docs\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "# Create Chroma DB with unique persist dir\n",
        "persist_dir = f\"chroma/chroma_MiniLM_300_50\"\n",
        "vectordb = Chroma.from_documents(chunks, emb, persist_directory=persist_dir)\n",
        "vectordb.persist()\n",
        "\n",
        "# Setup QA\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever(search_kwargs={\"k\": 4}), chain_type=\"stuff\")\n",
        "\n",
        "# Run Q&A\n",
        "results = []\n",
        "for q in questions:\n",
        "    a = qa.run(q)\n",
        "    results.append({\"Question\": q, \"Answer\": a})\n",
        "\n",
        "# Save results to CSV\n",
        "csv_path = f\"logs/results_MiniLM_300_50.csv\"\n",
        "pd.DataFrame(results).to_csv(csv_path, index=False)\n",
        "print(f\"Saved Q&A results to {csv_path}\")\n",
        "\n",
        "# Save run config\n",
        "rag_run_config = {\n",
        "    \"chunk_size\": 300,\n",
        "    \"chunk_overlap\": 50,\n",
        "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"llm\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    \"retriever_k\": 4\n",
        "}\n",
        "config_path = f\"reproduce_artifacts/rag_run_config_MiniLM_300_50.json\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(rag_run_config, f, indent=2)\n",
        "print(f\"Saved run config to {config_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QW6-czmJg0b8",
      "metadata": {
        "id": "QW6-czmJg0b8"
      },
      "source": [
        "## E5-Small  |  chunk_size=500, overlap=100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "121d4bfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "20edeb3358a04e588583148a9f07e8dc",
            "317f251e2caf43a48e0972aec276454a",
            "d750d62de09b4031bf2d8913afce1911",
            "c93eaf9f86664a1dbb919835d2c7a9ae",
            "82baae485887435085fd95ef1704522c",
            "54b11df50ad2414bb6922672c10b9ff5",
            "2dd43dfc47b1490da2a5973576e2b33a",
            "2f0a52bb2b274caf8f10371cc919ff76",
            "0127566ec2424caba583e78744f483b6",
            "b8ad90faa8d24fb5814115c5e55bd59e",
            "a3061aeecc674031b7c2f83c672f5b04",
            "ff8f626149294c14bfdfe2ac560a119e",
            "eeede9bab9534886a6b1ae2dd5fc57b0",
            "b154f2500d5f4835a1d79632417dccc9",
            "7f82c6f5283b41d9aeebef475c4a61c3",
            "53b597b55e144d42ae9e430818c390e1",
            "f60254be51874c03a2060e0323ed58fd",
            "9203b297e6a44216a25a6a72642da706",
            "04191d6d322448578d01d3677dd12e30",
            "7db173ba325c4ba18cb83394022d1586",
            "3924b144939d41298b67504b2d1d50de",
            "6711db005dbe4fc09abe45a2d359be38",
            "87bc87ac16e74162b15e285b2e97b791",
            "fac0a7381edd4c0fbc6975bccf8c8a1f",
            "3d8a36587fcd4227900527e0c732822d",
            "a5641ec007cb45bc8c0d426182be3e51",
            "0d8f208a96b04eb99503680c050d62c6",
            "bc7a58cebdc547b58e02ee5d5b5e6e7d",
            "0ba2d60d8fb94f7ca06f8ae3c05cc314",
            "3dbb1d0000714a83acb517dd66f65e3b",
            "2aa9eb468c034b329a8fbcf141977961",
            "fdbfc6435af94da8974b0353ac43309c",
            "f4a3fd4feef24ac9aa292921c87087a8",
            "8b6de3324a8446d892b076e5e447f9d6",
            "5e341fb218f74f249949aba77f6c8184",
            "b5aead7a44b74eb197c336e39ad679a0",
            "c5ed919c4e384439bc177c652c578de9",
            "a35e02c177e44d39a3c34513fe32bbf8",
            "d4d464a4af57491094ad463480438e23",
            "adac0f2969c74c40bf164e0e66fc7450",
            "00eef2f8df7148c09cb02204f1abca6f",
            "ab5817feec7542fe86d0b6ae22c6b526",
            "d9a54e8572c24532bc8ff6b9bb4278ee",
            "ae76b4acd27e4efab78ffaeb0098b87a",
            "6653919fa55840dea7f05c40c7a1054b",
            "ff3dc13fd36c45109b50dc38951edf8a",
            "c83324edc8454bb0b2d74a1c7773f665",
            "b8b951378ee1457ab16c90a52847b32c",
            "944e8786b73344ad8034d7675532aadf",
            "ab97d8805aa14fe6b7f757aefa181fb5",
            "d65d2049bf654c1086c2d178f4d6acd0",
            "d4756f75a1c84e6e8fd8604610cc76c2",
            "01d2498d4e9647e693964474782dde5b",
            "b17bcda2efdc4acbba173dae189a4a7c",
            "418f07fa3a3242bcb35f70eed6574dd5",
            "6c0e8283345e46e5a265b89681fc93f5",
            "df634e701dd84cdfad6a8637daed39f2",
            "bd4f96291c654b62a5f330011e736e91",
            "27adc9c47c794254b816b7927e490421",
            "4d18d94394744ce6881b7a3f627ebede",
            "87a89f961cda4aa58f2e7df85791b7f8",
            "69408d0aa405451c81f523bc17e07340",
            "b9c5ba8455ab483daf3655ba90a4aa86",
            "f572c95d083c4c5eaa1e31b6aa590405",
            "e14e0eb744da4f42867170e233502bd6",
            "69bea498ac814085a87eb9edee3b2232",
            "cbeb6c3b0cb54eb2aa9130fe971d4ddc",
            "e79ff729aec4477dac6f78bdc51003b0",
            "2b1536d0c80f4f08a9ebeb3d4ba54aea",
            "e35b03f6ed4044d3a69cd4684eebc87c",
            "93f0fc15236640dc8fd2dd1248e84c41",
            "b5d4a21235b346d79364b7b83fcca29a",
            "2aa4b7ca326f465f82c151638c75e416",
            "30a7244f3fb64f5ab48c83ae725f804f",
            "0933f47676134c40a9110d1ee25da024",
            "2fe43f20fafa4e2d9b2a88cfd771d56b",
            "397f58c7016243f6a9613d101d22ac5a",
            "2837ae7009814ecdb18db5ce9463fffc",
            "b0f447e1a71a442580d52034c9737ced",
            "a9f73be8ef1b4f10a68fd471b2bf8883",
            "44cf6f001c064644862afc14a10ff732",
            "52c75a6f4de4431e8ef7588f6dfc20f4",
            "6602dd563d5f4cf1ac93d9bce041bfa7",
            "e8dd44f098d14728b434eceb84899bef",
            "b752be9a9742419eb9b8fb812188dc89",
            "eb28bf80b1204257bbaaa40eae53f10f",
            "b6b0ea5e859b464ab5d6f95dbb1942ed",
            "2c4bfdde372449c7b21b78d2d7b8fbb2",
            "b64181b54083468cb4c288725d172e97",
            "92c82bcfa41b40ca94a94c5b9fe97640",
            "3337b9dd904145a09c4cb7c2fdf76c6b",
            "1f3916146fa543eb8c9d8d64dfcf7e40",
            "629041c2913547b38d0828cd91c87557",
            "4bcf731ec97146a09e27d24793adeb4e",
            "ebd9aa0ddba4477b8c766c135f863969",
            "93e41b41ade64c8b9d011541b9ed2237",
            "4a200b8e484349c2a73f2e7df53c9278",
            "97468356ca29460aa24c5d9940e93e74",
            "464cd15e9ade4100a7f496c43fa83569",
            "754b35b6146545dc999bd3b4c1cbe743",
            "541dea152ad349f48d929fc729d745ed",
            "0f969c721b304e27888dcc0511d6b02e",
            "330d240ca2744d11a2ad8949b4920b21",
            "638fbf9454a64b668bfa131d28aaf93d",
            "85048506c5ad454b8b254aa035a99a96",
            "a79c653c545c401bbbe27a3672f66caa",
            "1685a1b208dc4f608e26c32aa31d117e",
            "bcaa93ba524f42e09b19808a2e0328bb",
            "8209cdbcc2a94897b74d4a2629fa2ecc",
            "59ea907ea1a44b91891163ed80910b9d"
          ]
        },
        "id": "121d4bfb",
        "outputId": "bb19d78d-e425-4f79-91a6-64163f6b93a1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20edeb3358a04e588583148a9f07e8dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff8f626149294c14bfdfe2ac560a119e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87bc87ac16e74162b15e285b2e97b791",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b6de3324a8446d892b076e5e447f9d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6653919fa55840dea7f05c40c7a1054b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c0e8283345e46e5a265b89681fc93f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbeb6c3b0cb54eb2aa9130fe971d4ddc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2837ae7009814ecdb18db5ce9463fffc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b64181b54083468cb4c288725d172e97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "754b35b6146545dc999bd3b4c1cbe743",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Q&A results to logs/results_E5-small_500_100.csv\n",
            "Saved run config to reproduce_artifacts/rag_run_config_E5-small_500_100.json\n"
          ]
        }
      ],
      "source": [
        "# Q&A results for E5-small, chunk_size=500, overlap=100\n",
        "\n",
        "# Setup embedding model\n",
        "emb = SentenceTransformerEmbeddings(model_name=\"intfloat/e5-small-v2\")\n",
        "\n",
        "# Split docs\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "# Create Chroma DB with unique persist dir\n",
        "persist_dir = f\"chroma/chroma_E5-small_500_100\"\n",
        "vectordb = Chroma.from_documents(chunks, emb, persist_directory=persist_dir)\n",
        "vectordb.persist()\n",
        "\n",
        "# Setup QA\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever(search_kwargs={\"k\": 4}), chain_type=\"stuff\")\n",
        "\n",
        "# Run Q&A\n",
        "results = []\n",
        "for q in questions:\n",
        "    a = qa.run(q)\n",
        "    results.append({\"Question\": q, \"Answer\": a})\n",
        "\n",
        "# Save results to CSV\n",
        "csv_path = f\"logs/results_E5-small_500_100.csv\"\n",
        "pd.DataFrame(results).to_csv(csv_path, index=False)\n",
        "print(f\"Saved Q&A results to {csv_path}\")\n",
        "\n",
        "# Save run config\n",
        "rag_run_config = {\n",
        "    \"chunk_size\": 500,\n",
        "    \"chunk_overlap\": 100,\n",
        "    \"embedding_model\": \"intfloat/e5-small-v2\",\n",
        "    \"llm\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    \"retriever_k\": 4\n",
        "}\n",
        "config_path = f\"reproduce_artifacts/rag_run_config_E5-small_500_100.json\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(rag_run_config, f, indent=2)\n",
        "print(f\"Saved run config to {config_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9II45QAeiDfQ",
      "metadata": {
        "id": "9II45QAeiDfQ"
      },
      "source": [
        "## E5-Small  |  chunk_size=300, overlap=50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94c7e9e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94c7e9e9",
        "outputId": "f2caf1da-2c73-4fd5-c755-da5afb330c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Q&A results to logs/results_E5-small_300_50.csv\n",
            "Saved run config to reproduce_artifacts/rag_run_config_E5-small_300_50.json\n"
          ]
        }
      ],
      "source": [
        "# Q&A results for E5-small, chunk_size=300, overlap=50\n",
        "\n",
        "# Setup embedding model\n",
        "emb = SentenceTransformerEmbeddings(model_name=\"intfloat/e5-small-v2\")\n",
        "\n",
        "# Split docs\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "# Create Chroma DB with unique persist dir\n",
        "persist_dir = f\"chroma/chroma_E5-small_300_50\"\n",
        "vectordb = Chroma.from_documents(chunks, emb, persist_directory=persist_dir)\n",
        "vectordb.persist()\n",
        "\n",
        "# Setup QA\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever(search_kwargs={\"k\": 4}), chain_type=\"stuff\")\n",
        "\n",
        "# Run Q&A\n",
        "results = []\n",
        "for q in questions:\n",
        "    a = qa.run(q)\n",
        "    results.append({\"Question\": q, \"Answer\": a})\n",
        "\n",
        "# Save results to CSV\n",
        "csv_path = f\"logs/results_E5-small_300_50.csv\"\n",
        "pd.DataFrame(results).to_csv(csv_path, index=False)\n",
        "print(f\"Saved Q&A results to {csv_path}\")\n",
        "\n",
        "# Save run config\n",
        "rag_run_config = {\n",
        "    \"chunk_size\": 300,\n",
        "    \"chunk_overlap\": 50,\n",
        "    \"embedding_model\": \"intfloat/e5-small-v2\",\n",
        "    \"llm\": \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    \"retriever_k\": 4\n",
        "}\n",
        "config_path = f\"reproduce_artifacts/rag_run_config_E5-small_300_50.json\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(rag_run_config, f, indent=2)\n",
        "print(f\"Saved run config to {config_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rLUM1N2_5nJV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLUM1N2_5nJV",
        "outputId": "8bdd6516-001d-4015-9275-573835c26617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: logs/ (stored 0%)\n",
            "  adding: logs/results_E5-small_300_50.csv (deflated 63%)\n",
            "  adding: logs/results_E5-small_500_100.csv (deflated 61%)\n",
            "  adding: logs/results_MiniLM_300_50.csv (deflated 57%)\n",
            "  adding: logs/results_MiniLM_500_100.csv (deflated 59%)\n",
            "  adding: reproduce_artifacts/ (stored 0%)\n",
            "  adding: reproduce_artifacts/rag_run_config_E5-small_500_100.json (deflated 21%)\n",
            "  adding: reproduce_artifacts/rag_run_config_MiniLM_300_50.json (deflated 21%)\n",
            "  adding: reproduce_artifacts/rag_run_config_MiniLM_500_100.json (deflated 21%)\n",
            "  adding: reproduce_artifacts/rag_run_config_E5-small_300_50.json (deflated 20%)\n",
            "  adding: reproduce_artifacts/env_rag.json (deflated 32%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r TrackA.zip logs reproduce_artifacts\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}